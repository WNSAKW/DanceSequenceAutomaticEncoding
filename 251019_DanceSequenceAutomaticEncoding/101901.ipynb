{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd31a828-ef2c-4022-be8f-c48c07133907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 匯入套件 ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af67126f-997e-4cb8-94d5-4dbb5fc8f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: 讀取 CSV ---\n",
    "csv_path = \"./dance_csv/Ballet_1.csv\"  # 檔案名稱\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e989571f-d91d-4cd6-a256-75bee1014838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除 frame 欄，只取骨架點\n",
    "pose_cols = [c for c in df.columns if c != \"frame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc59d56e-de57-4b40-91fd-0a7d40e71c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把每個 ('x','y','z') 的字串轉成數字\n",
    "def parse_point(s):\n",
    "    # 去除括號與引號\n",
    "    s = s.strip(\"()\")\n",
    "    parts = [float(p.strip(\" '\")) for p in s.split(\",\")]\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4eaa0e-d0fb-4b42-85d5-ce863b6e613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "骨架資料 shape: (241, 99)\n"
     ]
    }
   ],
   "source": [
    "# 每幀 → 33 個點 × 3 維 = 99 維向量\n",
    "poses = []\n",
    "for i, row in df.iterrows():\n",
    "    pose = []\n",
    "    for c in pose_cols:\n",
    "        pose += parse_point(row[c])\n",
    "    poses.append(pose)\n",
    "\n",
    "poses = np.array(poses)\n",
    "print(\"骨架資料 shape:\", poses.shape)  # (N_frames, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fae3279-b561-40cb-849e-7ab47c385d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: 正規化 ---\n",
    "scaler = StandardScaler()\n",
    "poses = scaler.fit_transform(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24f3a43-14fc-422b-97ea-49811f52cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: 建立資料集 ---\n",
    "class PoseDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = PoseDataset(poses)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a28e3e-36ee-4483-ab6d-1a5fdddbf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: 定義 VQ-VAE ---\n",
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.embedding.weight.data.uniform_(-1/num_embeddings, 1/num_embeddings)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, dim)\n",
    "        distances = (\n",
    "            torch.sum(x**2, dim=1, keepdim=True)\n",
    "            + torch.sum(self.embedding.weight**2, dim=1)\n",
    "            - 2 * torch.matmul(x, self.embedding.weight.t())\n",
    "        )\n",
    "        encoding_indices = torch.argmin(distances, dim=1)\n",
    "        quantized = self.embedding(encoding_indices)\n",
    "        return quantized, encoding_indices\n",
    "\n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, input_dim=99, hidden_dim=64, latent_dim=32, num_embeddings=64):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        self.vq = VectorQuantizer(num_embeddings, latent_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_q, indices = self.vq(z)\n",
    "        x_recon = self.decoder(z_q)\n",
    "        return x_recon, indices, z, z_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3582e52-cfc5-449f-89c5-d6d110b65b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.0644\n",
      "Epoch 2/20, Loss: 1.0339\n",
      "Epoch 3/20, Loss: 1.0090\n",
      "Epoch 4/20, Loss: 1.0163\n",
      "Epoch 5/20, Loss: 1.0026\n",
      "Epoch 6/20, Loss: 1.0136\n",
      "Epoch 7/20, Loss: 1.0017\n",
      "Epoch 8/20, Loss: 1.0006\n",
      "Epoch 9/20, Loss: 1.0215\n",
      "Epoch 10/20, Loss: 1.0040\n",
      "Epoch 11/20, Loss: 0.9951\n",
      "Epoch 12/20, Loss: 1.0036\n",
      "Epoch 13/20, Loss: 1.0058\n",
      "Epoch 14/20, Loss: 0.9945\n",
      "Epoch 15/20, Loss: 0.9955\n",
      "Epoch 16/20, Loss: 0.9953\n",
      "Epoch 17/20, Loss: 0.9938\n",
      "Epoch 18/20, Loss: 0.9824\n",
      "Epoch 19/20, Loss: 0.9814\n",
      "Epoch 20/20, Loss: 0.9664\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: 訓練 ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = VQVAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_recon, indices, z, z_q = model(batch)\n",
    "        recon_loss = loss_fn(x_recon, batch)\n",
    "        vq_loss = torch.mean((z_q.detach() - z)**2) + 0.25 * torch.mean((z_q - z.detach())**2)\n",
    "        loss = recon_loss + vq_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/20, Loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07d71b17-a9ef-42aa-a8e0-f7abc29df713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: 轉換成符號序列 ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_indices = []\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        _, indices, _, _ = model(batch)\n",
    "        all_indices.extend(indices.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1760df6a-0fd4-49fa-8dcd-dd89dc4420b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "符號序列預覽： QWNMQTAJBRVTKBNBJNYGOEGGJUJEYBKHJPFFESJCBETBKUGUPEJDIJJRFDMMFJJKJHJGJJJIJTEBBTTUEGBITDKNLGUBJFVWFJYWFOENTQJJCEKTTQJDLOGYOLXJUROTBWTJFNQENTWLJNRNGJHFOIMWULWODPBJSMOOTLUEACQEENTJPLJMYQFOGJPAIJPJBQNLJOSL\n"
     ]
    }
   ],
   "source": [
    "# --- Step 7: 生成符號對應 ---\n",
    "symbols = [chr(65 + (i % 26)) for i in all_indices]  # A-Z 符號循環\n",
    "sequence = \"\".join(symbols)\n",
    "print(\"符號序列預覽：\", sequence[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f00f1e-553e-4f2c-8aa0-0438eb01ec9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
