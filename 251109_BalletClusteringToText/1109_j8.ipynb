{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6343ebb3-1fa7-450a-844b-a99f59573269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# LSTM 舞蹈敘事生成器：JSON(frames) -> 詩意段落\n",
    "# ==========================================================\n",
    "\n",
    "import json, os, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b349ba-04d7-4993-8024-b5aba4d9e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- CONFIG ----------------\n",
    "JSON_PATH = \"ballet_multi_part_clusters.json\"\n",
    "TARGET_KEY = \"Ballet_40.csv\"     # 可任意更換\n",
    "WINDOW_LEN = 8\n",
    "STEP = 4\n",
    "MAX_SAMPLES = None\n",
    "EMBEDDING_DIM = 64\n",
    "LATENT_DIM = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "MODEL_DIR = \"ballet_lstm_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beeeed27-867f-4eee-a9e7-58ff28a58631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- MOVEMENT DICTIONARIES ----------------\n",
    "BODY_PARTS = [\"Head\",\"LeftArm\",\"RightArm\",\"LeftLeg\",\"RightLeg\",\"Torso\"]\n",
    "movement_dict = {\n",
    "    \"Head\": {0:\"頭部直立\",1:\"微微低頭\",2:\"頭向左偏\",3:\"頭向右偏\",4:\"頭部快速轉動\",5:\"頭部不穩定\"},\n",
    "    \"LeftArm\": {0:\"左手自然下垂\",1:\"左手半舉\",2:\"左手高舉\",3:\"左手向前伸\",4:\"左手橫向展開\",5:\"左手轉換中\"},\n",
    "    \"RightArm\": {0:\"右手自然下垂\",1:\"右手舉至中段高度\",2:\"右手完全抬高\",3:\"右手橫向展開\",4:\"右手向前伸出\",5:\"右手轉換中\"},\n",
    "    \"LeftLeg\": {0:\"左腳著地站立\",1:\"左腳抬起\",2:\"左腳側向伸展\",3:\"左腳後伸\",4:\"左腳屈膝準備動作\",5:\"左腳跳躍或過渡\"},\n",
    "    \"RightLeg\": {0:\"右腳著地站立\",1:\"右腳抬起\",2:\"右腳伸展或踢腿\",3:\"右腳後伸\",4:\"右腳屈膝準備跳或轉\",5:\"右腳快速移動或跳躍\"},\n",
    "    \"Torso\": {0:\"軀幹直立穩定\",1:\"軀幹微前傾\",2:\"軀幹後仰\",3:\"軀幹側傾\",4:\"軀幹扭轉\",5:\"軀幹不穩定\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6422a33f-8dc3-4890-a8fe-dd384230cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- LOAD FRAMES ----------------\n",
    "def load_frames(json_path, key):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    if key not in data:\n",
    "        raise KeyError(f\"{key} not found in JSON. Available keys: {list(data.keys())}\")\n",
    "    frames = [list(map(int, fr)) for fr in data[key] if len(fr) >= 6]\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce844b0b-dd95-45c1-afb2-d1a6a2050870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- POETIC TEMPLATES ----------------\n",
    "POETIC_TEMPLATES = [\n",
    "    \"舞者{desc}，彷彿{image}。\",\n",
    "    \"她{desc}，像是在{image}。\",\n",
    "    \"{desc}，如同{image}在呼吸。\",\n",
    "    \"在光裡，舞者{desc}，那是{image}的瞬間。\",\n",
    "    \"當{desc}時，她的心也{image}。\",\n",
    "    \"{desc}之間，像是記憶被風吹動。\",\n",
    "    \"她在{desc}之間，尋找{image}。\",\n",
    "    \"隨著光線的流動，{desc}，那是一種{image}。\",\n",
    "    \"靜止中，{desc}，彷彿時間在{image}。\"\n",
    "]\n",
    "\n",
    "SYMBOLIC_MAP = {\n",
    "    \"高舉\": [\"追尋光\", \"擁抱黎明\", \"伸向天空\"],\n",
    "    \"抬起\": [\"掙脫地心\", \"伸向遠方\", \"指向未來\"],\n",
    "    \"展開\": [\"釋放\", \"綻放\", \"開啟\"],\n",
    "    \"扭轉\": [\"時間的皺摺\", \"內在的回聲\", \"意識的迴旋\"],\n",
    "    \"低頭\": [\"回望\", \"沉思\", \"與影子對話\"],\n",
    "    \"伸\": [\"觸摸未知\", \"尋找平衡\", \"撫過空氣\"],\n",
    "    \"跳躍\": [\"掙脫地心\", \"飛起的願望\", \"破碎的重力\"],\n",
    "    \"後仰\": [\"沉入記憶\", \"回到夢裡\", \"墜入過去\"],\n",
    "    \"側傾\": [\"在邊界搖晃\", \"尋找失重\", \"接近流動\"],\n",
    "    \"穩定\": [\"成為風的軸心\", \"讓時間靜止\", \"在呼吸裡存在\"]\n",
    "}\n",
    "\n",
    "CONNECTORS = [\"接著\", \"隨後\", \"同時\", \"之後\", \"此刻\", \"慢慢地\", \"忽然\", \"她感覺到\", \"光線轉換之時\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284ecbb8-e1e0-4148-930e-44d42cdd66a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- RULE-BASED POETRY ----------------\n",
    "def window_to_rule_poetry(window_frames):\n",
    "    n = len(window_frames)\n",
    "    changes = {i: set() for i in range(6)}\n",
    "    for i in range(1, n):\n",
    "        for j in range(6):\n",
    "            if window_frames[i][j] != window_frames[i-1][j]:\n",
    "                changes[j].add(window_frames[i][j])\n",
    "\n",
    "    descs = []\n",
    "    if changes[1] or changes[2]:\n",
    "        if changes[1] and changes[2]:\n",
    "            descs.append(\"雙手\" + random.choice([\"高舉\", \"展開\", \"伸出\"]))\n",
    "        elif changes[1]:\n",
    "            descs.append(\"左手\" + random.choice([\"舉起\", \"伸出\", \"下垂\"]))\n",
    "        elif changes[2]:\n",
    "            descs.append(\"右手\" + random.choice([\"舉起\", \"伸出\", \"下垂\"]))\n",
    "    if changes[3] or changes[4]:\n",
    "        if changes[3] and changes[4]:\n",
    "            descs.append(\"雙腿\" + random.choice([\"站穩\", \"抬起\", \"伸展\"]))\n",
    "        elif changes[3]:\n",
    "            descs.append(\"左腳\" + random.choice([\"抬起\", \"伸展\", \"著地\"]))\n",
    "        elif changes[4]:\n",
    "            descs.append(\"右腳\" + random.choice([\"抬起\", \"伸展\", \"著地\"]))\n",
    "    if changes[5]:\n",
    "        descs.append(\"軀幹\" + random.choice([\"前傾\", \"後仰\", \"扭轉\", \"直立\"]))\n",
    "    if changes[0]:\n",
    "        descs.append(\"頭部\" + random.choice([\"低垂\", \"轉向\", \"上揚\"]))\n",
    "    if not descs:\n",
    "        descs = [\"姿態平穩\"]\n",
    "\n",
    "    desc = \" \".join(descs)\n",
    "    matched_keys = [k for k in SYMBOLIC_MAP.keys() if any(k in d for d in descs)]\n",
    "    if matched_keys:\n",
    "        key = random.choice(matched_keys)\n",
    "        image = random.choice(SYMBOLIC_MAP[key])\n",
    "    else:\n",
    "        image = random.choice(sum(SYMBOLIC_MAP.values(), []))\n",
    "    template = random.choice(POETIC_TEMPLATES)\n",
    "    return template.format(desc=desc, image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f05cda-9c7f-4842-8ed6-59b228b679d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- BUILD DATASET ----------------\n",
    "def build_dataset(frames, window_len, step, max_samples=None):\n",
    "    X_texts, Y_texts = [], []\n",
    "    n = len(frames)\n",
    "    for start in range(0, n - window_len + 1, step):\n",
    "        win = frames[start:start + window_len]\n",
    "        inp = \" | \".join([\" \".join(map(str, f)) for f in win])\n",
    "        out = \"\\t\" + window_to_rule_poetry(win) + \"\\n\"\n",
    "        X_texts.append(inp)\n",
    "        Y_texts.append(out)\n",
    "        if max_samples and len(X_texts) >= max_samples:\n",
    "            break\n",
    "    return X_texts, Y_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8753c8-f9ce-4017-b62f-e1b39aee8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- TOKENIZERS ----------------\n",
    "def prepare_tokenizers(X_texts, Y_texts):\n",
    "    tok_in = Tokenizer(filters='', split=' ', oov_token='<OOV>')\n",
    "    tok_in.fit_on_texts(X_texts)\n",
    "    tok_out = Tokenizer(char_level=True, filters='', oov_token='<OOV>')\n",
    "    tok_out.fit_on_texts(Y_texts)\n",
    "    return tok_in, tok_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c6a5afe-f08d-469f-9327-e4872c4732aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- SEQ2SEQ ----------------\n",
    "def build_seq2seq(num_encoder_tokens, num_decoder_tokens):\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    enc_emb = Embedding(num_encoder_tokens, EMBEDDING_DIM, mask_zero=True)(encoder_inputs)\n",
    "    _, state_h, state_c = LSTM(LATENT_DIM, return_state=True)(enc_emb)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    dec_emb_layer = Embedding(num_decoder_tokens, EMBEDDING_DIM, mask_zero=True)\n",
    "    dec_emb = dec_emb_layer(decoder_inputs)\n",
    "    decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "    dec_out, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "    dec_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    dec_out = dec_dense(dec_out)\n",
    "    model = Model([encoder_inputs, decoder_inputs], dec_out)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    return model, (encoder_inputs, encoder_states, dec_emb_layer, decoder_lstm, dec_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786051a0-acb3-4720-b486-70285b4a490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- TRAIN + SAVE ----------------\n",
    "def train_and_save_model(X_texts, Y_texts):\n",
    "    tok_in, tok_out = prepare_tokenizers(X_texts, Y_texts)\n",
    "    X_seq = tok_in.texts_to_sequences(X_texts)\n",
    "    Y_seq = tok_out.texts_to_sequences(Y_texts)\n",
    "    max_enc_len = max(len(s) for s in X_seq)\n",
    "    max_dec_len = max(len(s) for s in Y_seq)\n",
    "    enc_in = pad_sequences(X_seq, maxlen=max_enc_len, padding='post')\n",
    "    dec_in = pad_sequences([s[:-1] for s in Y_seq], maxlen=max_dec_len - 1, padding='post')\n",
    "    dec_tg = pad_sequences([s[1:] for s in Y_seq], maxlen=max_dec_len - 1, padding='post')\n",
    "    dec_tg = np.expand_dims(dec_tg, -1)\n",
    "\n",
    "    model, comp = build_seq2seq(len(tok_in.word_index)+1, len(tok_out.word_index)+1)\n",
    "    model.fit([enc_in, dec_in], dec_tg, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.1)\n",
    "    return {\"model\": model, \"tokenizer_in\": tok_in, \"tokenizer_out\": tok_out,\n",
    "            \"max_enc_len\": max_enc_len, \"max_dec_len\": max_dec_len,\n",
    "            \"encoder_inputs\": comp[0], \"encoder_states\": comp[1],\n",
    "            \"dec_emb_layer\": comp[2], \"decoder_lstm\": comp[3], \"decoder_dense\": comp[4],\n",
    "            \"window_len\": WINDOW_LEN, \"step\": STEP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a16067f-ed7a-4154-be6d-94e17a4c5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- PARAGRAPH DECODER ----------------\n",
    "def decode_paragraph(frames, artefacts, top_k=10, temperature=0.8, connector_prob=0.3):\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    paragraph, prev_state = [], None\n",
    "    for i in range(0, len(frames) - artefacts['window_len'] + 1, artefacts['step']):\n",
    "        win = frames[i:i + artefacts['window_len']]\n",
    "        inp = \" | \".join([\" \".join(map(str, f)) for f in win])\n",
    "        paragraph.append(window_to_rule_poetry(win))\n",
    "        if random.random() < connector_prob:\n",
    "            paragraph.append(random.choice(CONNECTORS) + \"，\")\n",
    "    return smart_paragraph_formatter(paragraph)\n",
    "\n",
    "def smart_paragraph_formatter(sentences, max_per_line=3):\n",
    "    lines, buf = [], []\n",
    "    for s in sentences:\n",
    "        buf.append(s.strip())\n",
    "        if len(buf) >= random.randint(2, max_per_line):\n",
    "            lines.append(\" \".join(buf))\n",
    "            buf = []\n",
    "    if buf:\n",
    "        lines.append(\" \".join(buf))\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a1a98b-df06-4564-ad61-08137d4dfe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- MAIN ----------------\n",
    "def run_pipeline():\n",
    "    frames = load_frames(JSON_PATH, TARGET_KEY)\n",
    "    print(\"Loaded frames:\", len(frames))\n",
    "    X_texts, Y_texts = build_dataset(frames, WINDOW_LEN, STEP, MAX_SAMPLES)\n",
    "    print(\"Built dataset samples:\", len(X_texts))\n",
    "    artefacts = train_and_save_model(X_texts, Y_texts)\n",
    "    print(\"\\n==== Adaptive Paragraph Inference Demo ====\")\n",
    "    paragraph = decode_paragraph(frames, artefacts, top_k=20, temperature=1.0)\n",
    "    print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7de65110-6a2b-4f3d-bb54-7b150e52744e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded frames: 593\n",
      "Built dataset samples: 147\n",
      "Epoch 1/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 179ms/step - loss: 4.7995 - val_loss: 4.7369\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 4.4885 - val_loss: 4.2362\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 4.0561 - val_loss: 4.0445\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 3.8779 - val_loss: 3.9534\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.7190 - val_loss: 3.8336\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 3.6164 - val_loss: 3.7896\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 3.5168 - val_loss: 3.8155\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 3.4577 - val_loss: 3.7283\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 3.3536 - val_loss: 3.6895\n",
      "Epoch 10/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 3.2676 - val_loss: 3.5921\n",
      "Epoch 11/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 3.1338 - val_loss: 3.4325\n",
      "Epoch 12/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 3.0088 - val_loss: 3.3829\n",
      "Epoch 13/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 2.8732 - val_loss: 3.1933\n",
      "Epoch 14/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 2.7393 - val_loss: 3.0394\n",
      "Epoch 15/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.6192 - val_loss: 2.9294\n",
      "Epoch 16/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.4854 - val_loss: 2.8189\n",
      "Epoch 17/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 2.3689 - val_loss: 2.6936\n",
      "Epoch 18/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 2.2633 - val_loss: 2.5914\n",
      "Epoch 19/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 2.1514 - val_loss: 2.5268\n",
      "Epoch 20/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2.0466 - val_loss: 2.3797\n",
      "\n",
      "==== Adaptive Paragraph Inference Demo ====\n",
      "當雙手展開 右腳著地 軀幹扭轉時，她的心也綻放。 她雙手展開 軀幹扭轉，像是在內在的回聲。 忽然，\n",
      "靜止中，雙手展開 雙腿站穩 軀幹前傾 頭部轉向，彷彿時間在綻放。 隨著光線的流動，雙手展開 雙腿抬起 軀幹扭轉 頭部上揚，那是一種開啟。\n",
      "她雙手伸出 右腳著地 軀幹直立 頭部低垂，像是在觸摸未知。 隨著光線的流動，雙手展開 右腳抬起 頭部轉向，那是一種指向未來。 當雙手高舉 雙腿抬起 軀幹後仰 頭部低垂時，她的心也掙脫地心。\n",
      "此刻， 隨著光線的流動，雙手高舉 右腳著地 軀幹扭轉 頭部上揚，那是一種追尋光。\n",
      "她在左手伸出 雙腿站穩 頭部低垂之間，尋找尋找平衡。 當雙腿伸展 頭部低垂時，她的心也撫過空氣。\n",
      "隨著光線的流動，雙手展開 雙腿抬起 軀幹直立 頭部上揚，那是一種伸向遠方。 她雙手伸出 雙腿抬起 軀幹後仰 頭部上揚，像是在觸摸未知。 接著，\n",
      "在光裡，舞者雙手伸出 雙腿抬起，那是伸向遠方的瞬間。 當雙手展開 雙腿站穩 軀幹扭轉 頭部低垂時，她的心也內在的回聲。 右手舉起 右腳著地 軀幹直立 頭部轉向，如同時間的皺摺在呼吸。\n",
      "她在右手舉起 右腳抬起 軀幹前傾 頭部上揚之間，尋找掙脫地心。 舞者右手伸出 右腳著地 軀幹前傾 頭部轉向，彷彿尋找平衡。\n",
      "右腳伸展 頭部低垂之間，像是記憶被風吹動。 光線轉換之時，\n",
      "她右手伸出 右腳伸展 頭部轉向，像是在觸摸未知。 舞者雙手高舉 右腳抬起 軀幹扭轉 頭部上揚，彷彿內在的回聲。 她感覺到，\n",
      "隨著光線的流動，雙手展開 右腳著地 軀幹直立 頭部上揚，那是一種釋放。 她感覺到，\n",
      "舞者右手伸出 雙腿抬起 軀幹扭轉 頭部上揚，彷彿觸摸未知。 同時，\n",
      "在光裡，舞者雙手展開 雙腿伸展，那是綻放的瞬間。 慢慢地， 雙手伸出 右腳抬起 頭部轉向之間，像是記憶被風吹動。\n",
      "她雙手展開 雙腿抬起 頭部上揚，像是在指向未來。 接著， 隨著光線的流動，雙手高舉 雙腿抬起 頭部低垂，那是一種伸向天空。\n",
      "接著， 雙手高舉 左腳伸展 軀幹扭轉 頭部低垂，如同意識的迴旋在呼吸。 之後，\n",
      "當左手伸出 左腳伸展 軀幹前傾 頭部上揚時，她的心也觸摸未知。 隨著光線的流動，雙腿抬起 軀幹後仰 頭部上揚，那是一種沉入記憶。\n",
      "光線轉換之時， 當雙手展開 右腳抬起 軀幹直立時，她的心也指向未來。\n",
      "舞者雙手展開 右腳伸展 軀幹後仰，彷彿墜入過去。 當雙手展開 右腳著地 軀幹扭轉 頭部上揚時，她的心也意識的迴旋。\n",
      "在光裡，舞者雙手伸出 右腳抬起 軀幹扭轉 頭部轉向，那是內在的回聲的瞬間。 之後，\n",
      "在光裡，舞者雙手高舉 右腳抬起 軀幹前傾 頭部轉向，那是伸向遠方的瞬間。 光線轉換之時， 舞者右手下垂 雙腿伸展 頭部低垂，彷彿觸摸未知。\n",
      "隨著光線的流動，右手伸出 雙腿伸展 頭部低垂，那是一種尋找平衡。 當右手舉起 雙腿站穩時，她的心也釋放。\n",
      "雙手展開 右腳抬起 軀幹扭轉，如同綻放在呼吸。 舞者左手舉起 右腳著地 頭部上揚，彷彿追尋光。 她在雙手伸出 右腳著地 軀幹前傾 頭部轉向之間，尋找觸摸未知。\n",
      "雙手高舉 雙腿抬起 軀幹前傾 頭部轉向之間，像是記憶被風吹動。 舞者雙手高舉 雙腿伸展 軀幹後仰 頭部轉向，彷彿墜入過去。\n",
      "隨著光線的流動，雙手展開 雙腿伸展 軀幹前傾 頭部低垂，那是一種釋放。 當雙手高舉 雙腿抬起 軀幹前傾 頭部低垂時，她的心也追尋光。\n",
      "雙手伸出 雙腿站穩 軀幹直立 頭部上揚之間，像是記憶被風吹動。 隨著光線的流動，雙手伸出 雙腿抬起 軀幹直立 頭部低垂，那是一種伸向遠方。\n",
      "此刻， 雙手高舉 雙腿站穩 軀幹扭轉 頭部低垂，如同擁抱黎明在呼吸。 左手伸出 雙腿伸展 軀幹後仰 頭部低垂之間，像是記憶被風吹動。\n",
      "在光裡，舞者左手伸出 雙腿伸展 軀幹扭轉 頭部低垂，那是時間的皺摺的瞬間。 她雙手伸出 雙腿站穩 軀幹後仰 頭部低垂，像是在回到夢裡。 隨著光線的流動，雙手高舉 雙腿伸展 軀幹直立 頭部低垂，那是一種尋找平衡。\n",
      "舞者雙手高舉 右腳伸展 軀幹後仰 頭部轉向，彷彿沉入記憶。 隨著光線的流動，左手伸出 右腳伸展 軀幹後仰 頭部轉向，那是一種觸摸未知。 她在雙手高舉 雙腿站穩 軀幹扭轉 頭部低垂之間，尋找伸向天空。\n",
      "她在雙手伸出 雙腿抬起 軀幹前傾 頭部低垂之間，尋找撫過空氣。 慢慢地， 在光裡，舞者右手下垂 雙腿伸展 軀幹前傾 頭部低垂，那是尋找平衡的瞬間。\n",
      "當右手舉起 雙腿站穩 軀幹直立時，她的心也接近流動。 雙手展開 雙腿伸展 軀幹後仰之間，像是記憶被風吹動。\n",
      "舞者雙手展開 雙腿抬起 軀幹直立 頭部低垂，彷彿掙脫地心。 隨著光線的流動，雙手高舉 雙腿抬起 軀幹前傾 頭部轉向，那是一種掙脫地心。 當雙手伸出 雙腿伸展時，她的心也撫過空氣。\n",
      "隨著光線的流動，雙手展開 雙腿站穩 軀幹扭轉，那是一種綻放。 接著，\n",
      "她在雙手伸出 雙腿伸展 軀幹直立 頭部轉向之間，尋找尋找平衡。 舞者雙手高舉 雙腿站穩 軀幹後仰 頭部低垂，彷彿沉入記憶。 之後，\n",
      "舞者雙手伸出 雙腿站穩 軀幹扭轉 頭部低垂，彷彿觸摸未知。 在光裡，舞者雙腿站穩 軀幹後仰，那是沉入記憶的瞬間。 她雙腿站穩 軀幹直立 頭部上揚，像是在墜入過去。\n",
      "在光裡，舞者雙腿抬起 軀幹扭轉 頭部轉向，那是時間的皺摺的瞬間。 右手伸出 雙腿伸展 軀幹前傾 頭部低垂，如同尋找平衡在呼吸。 靜止中，雙手高舉 雙腿抬起 軀幹後仰 頭部低垂，彷彿時間在伸向遠方。\n",
      "她雙手高舉 雙腿站穩 軀幹前傾，像是在擁抱黎明。 光線轉換之時， 在光裡，舞者雙手展開 雙腿抬起，那是綻放的瞬間。\n",
      "隨著光線的流動，右手伸出 右腳著地 軀幹後仰，那是一種尋找平衡。 她感覺到， 隨著光線的流動，雙手高舉 雙腿抬起 軀幹後仰，那是一種掙脫地心。\n",
      "舞者雙手伸出 雙腿站穩，彷彿觸摸未知。 當雙手高舉 右腳抬起 軀幹前傾時，她的心也指向未來。 當雙手伸出 雙腿伸展 軀幹後仰 頭部上揚時，她的心也回到夢裡。\n",
      "她在右手舉起 雙腿伸展 軀幹扭轉 頭部上揚之間，尋找時間的皺摺。 她感覺到，\n",
      "當左腳著地 頭部低垂時，她的心也追尋光。 舞者左腳抬起 軀幹直立 頭部上揚，彷彿掙脫地心。\n",
      "忽然， 在光裡，舞者右手舉起 雙腿伸展 軀幹直立 頭部轉向，那是尋找平衡的瞬間。\n",
      "雙手展開 雙腿站穩 軀幹扭轉 頭部上揚，如同意識的迴旋在呼吸。 她在雙手伸出 雙腿站穩 軀幹後仰 頭部上揚之間，尋找沉入記憶。\n",
      "此刻， 她在雙手高舉 雙腿站穩 軀幹直立 頭部上揚之間，尋找擁抱黎明。\n",
      "同時， 她左手下垂 雙腿伸展 軀幹前傾 頭部轉向，像是在撫過空氣。\n",
      "隨著光線的流動，左手舉起 雙腿伸展 軀幹直立，那是一種觸摸未知。 隨後，\n",
      "她在左手伸出 雙腿伸展 頭部上揚之間，尋找尋找平衡。 接著， 她在左手伸出 雙腿站穩 軀幹直立 頭部低垂之間，尋找撫過空氣。\n",
      "左手下垂 左腳著地 軀幹前傾之間，像是記憶被風吹動。 她在左手下垂 左腳抬起 軀幹扭轉之間，尋找意識的迴旋。\n",
      "慢慢地， 隨著光線的流動，左手下垂 左腳伸展 軀幹後仰 頭部低垂，那是一種回到夢裡。\n",
      "在光裡，舞者左手伸出 左腳伸展 軀幹扭轉 頭部低垂，那是撫過空氣的瞬間。 此刻， 靜止中，左手下垂 左腳著地，彷彿時間在追尋光。\n",
      "她感覺到， 她左手伸出 雙腿伸展 頭部低垂，像是在尋找平衡。\n",
      "忽然， 在光裡，舞者雙手高舉 雙腿伸展 軀幹後仰 頭部上揚，那是追尋光的瞬間。\n",
      "同時， 雙手展開 雙腿伸展 軀幹前傾 頭部低垂之間，像是記憶被風吹動。 隨著光線的流動，左手伸出 雙腿伸展 軀幹直立 頭部低垂，那是一種尋找平衡。\n",
      "雙手展開 雙腿抬起 軀幹直立 頭部低垂之間，像是記憶被風吹動。 雙手伸出 雙腿抬起 軀幹直立 頭部上揚，如同指向未來在呼吸。\n",
      "同時， 在光裡，舞者雙手展開 雙腿抬起 軀幹前傾 頭部低垂，那是綻放的瞬間。 雙手伸出 左腳伸展 頭部上揚之間，像是記憶被風吹動。\n",
      "接著， 她雙手高舉 左腳伸展 頭部低垂，像是在尋找平衡。\n",
      "光線轉換之時， 當雙手伸出 右腳抬起時，她的心也伸向遠方。 她感覺到，\n",
      "她在雙手伸出 右腳抬起之間，尋找觸摸未知。 在光裡，舞者雙手高舉 雙腿站穩，那是伸向天空的瞬間。\n",
      "在光裡，舞者雙手高舉 雙腿伸展 軀幹後仰 頭部上揚，那是擁抱黎明的瞬間。 隨著光線的流動，雙手伸出 雙腿伸展 軀幹直立 頭部上揚，那是一種尋找平衡。\n",
      "在光裡，舞者雙手伸出 右腳著地 軀幹後仰，那是觸摸未知的瞬間。 之後， 隨著光線的流動，雙手伸出 右腳著地 頭部轉向，那是一種尋找平衡。\n",
      "靜止中，右手舉起 雙腿站穩 頭部低垂，彷彿時間在尋找平衡。 同時， 當雙手伸出 雙腿抬起 頭部上揚時，她的心也伸向遠方。\n",
      "在光裡，舞者雙手高舉 雙腿抬起 頭部上揚，那是伸向天空的瞬間。 在光裡，舞者雙手高舉 右腳著地，那是伸向天空的瞬間。\n",
      "她在雙手高舉 雙腿伸展 軀幹前傾 頭部上揚之間，尋找撫過空氣。 雙手高舉 雙腿抬起 軀幹後仰 頭部轉向之間，像是記憶被風吹動。\n",
      "舞者左腳伸展 軀幹直立 頭部低垂，彷彿觸摸未知。 靜止中，左腳伸展 軀幹直立 頭部低垂，彷彿時間在觸摸未知。 當左腳著地 軀幹扭轉 頭部轉向時，她的心也時間的皺摺。\n",
      "她感覺到， 左腳伸展 軀幹直立 頭部轉向，如同撫過空氣在呼吸。\n",
      "隨著光線的流動，雙手展開 雙腿站穩 軀幹直立 頭部低垂，那是一種綻放。 同時， 舞者雙手伸出 雙腿伸展 軀幹前傾 頭部轉向，彷彿尋找平衡。\n",
      "當右手舉起 雙腿抬起 軀幹扭轉 頭部上揚時，她的心也內在的回聲。 舞者左手下垂 雙腿伸展 軀幹扭轉 頭部低垂，彷彿撫過空氣。 忽然，\n",
      "隨著光線的流動，左手伸出 雙腿站穩 頭部上揚，那是一種撫過空氣。 靜止中，左手舉起 雙腿站穩 軀幹前傾 頭部轉向，彷彿時間在時間的皺摺。 慢慢地，\n",
      "舞者雙手伸出 雙腿站穩 軀幹扭轉 頭部低垂，彷彿時間的皺摺。 當右手伸出 雙腿站穩 頭部低垂時，她的心也觸摸未知。\n",
      "接著， 右手伸出 雙腿伸展 頭部低垂，如同觸摸未知在呼吸。\n",
      "隨著光線的流動，右手伸出 雙腿站穩 軀幹扭轉，那是一種意識的迴旋。 舞者左手下垂 雙腿伸展 軀幹後仰 頭部上揚，彷彿尋找平衡。\n",
      "當左手舉起 雙腿抬起 軀幹扭轉 頭部低垂時，她的心也掙脫地心。 在光裡，舞者左手伸出 雙腿站穩，那是撫過空氣的瞬間。 她左手舉起 雙腿抬起，像是在指向未來。\n",
      "雙腿抬起之間，像是記憶被風吹動。 光線轉換之時，\n",
      "雙手展開 雙腿站穩 軀幹扭轉 頭部上揚，如同綻放在呼吸。 同時， 雙手伸出 雙腿伸展 軀幹直立 頭部轉向之間，像是記憶被風吹動。\n",
      "她在雙腿站穩之間，尋找內在的回聲。 隨後， 隨著光線的流動，右手伸出 右腳伸展 頭部上揚，那是一種尋找平衡。\n",
      "雙手高舉 右腳著地 頭部轉向，如同擁抱黎明在呼吸。 她在雙手伸出 雙腿伸展 軀幹直立 頭部轉向之間，尋找撫過空氣。 光線轉換之時，\n",
      "她在雙手高舉 雙腿抬起 軀幹直立 頭部低垂之間，尋找指向未來。 慢慢地，\n",
      "舞者右腳著地 軀幹直立，彷彿意識的迴旋。 隨後，\n",
      "右腳著地 軀幹扭轉之間，像是記憶被風吹動。 光線轉換之時， 靜止中，右腳抬起，彷彿時間在指向未來。\n",
      "慢慢地， 靜止中，左手下垂 右腳伸展 軀幹前傾，彷彿時間在尋找平衡。 她在雙手高舉 右腳著地 軀幹前傾 頭部低垂之間，尋找伸向天空。\n",
      "她雙手展開 右腳伸展 軀幹前傾 頭部上揚，像是在尋找平衡。 光線轉換之時，\n"
     ]
    }
   ],
   "source": [
    "# ---------------- EXECUTE ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "        try: tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except: pass\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e71a1c-74b5-4f40-9dab-0cec300028ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
